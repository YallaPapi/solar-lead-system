# Task ID: 15
# Title: Fix OpenAI Threading and Chat API
# Status: pending
# Dependencies: 14
# Priority: medium
# Description: Resolve OpenAI threading and timeout issues in the chat API to ensure stable AI chat functionality for demo sites.
# Details:
Enhance the chat API endpoint to handle OpenAI Assistant API interactions reliably:

1. Implement proper thread management for OpenAI conversations
2. Add timeout handling and retry logic for API calls
3. Improve error handling for various failure scenarios
4. Implement thread cleanup to prevent resource exhaustion

Implementation:

```javascript
// pages/api/chat.js
import OpenAI from 'openai'
import { getCompanyAssistant } from '../../lib/redis'

// Initialize OpenAI client
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

// Maximum retries for OpenAI API calls
const MAX_RETRIES = 3
// Timeout for run completion (in milliseconds)
const RUN_TIMEOUT = 60000

/**
 * Retry an OpenAI API call with exponential backoff
 * @param {Function} apiCall - The API call function to retry
 * @param {number} maxRetries - Maximum number of retries
 * @returns {Promise} - Result of the API call
 */
async function retryWithBackoff(apiCall, maxRetries = MAX_RETRIES) {
  let lastError
  
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await apiCall()
    } catch (error) {
      console.error(`API call failed (attempt ${attempt + 1}/${maxRetries}):`, error)
      lastError = error
      
      // Only retry on specific error types
      if (!error.status || ![429, 500, 502, 503, 504].includes(error.status)) {
        throw error
      }
      
      // Exponential backoff
      const delay = Math.min(1000 * Math.pow(2, attempt), 10000)
      await new Promise(resolve => setTimeout(resolve, delay))
    }
  }
  
  throw lastError
}

/**
 * Wait for run completion with timeout
 * @param {string} threadId - OpenAI thread ID
 * @param {string} runId - OpenAI run ID
 * @param {number} timeout - Timeout in milliseconds
 * @returns {object} - Completed run
 */
async function waitForRunCompletion(threadId, runId, timeout = RUN_TIMEOUT) {
  const startTime = Date.now()
  
  while (Date.now() - startTime < timeout) {
    const run = await retryWithBackoff(() => 
      openai.beta.threads.runs.retrieve(threadId, runId)
    )
    
    if (run.status === 'completed') {
      return run
    }
    
    if (['failed', 'cancelled', 'expired'].includes(run.status)) {
      throw new Error(`Run failed with status: ${run.status}`)
    }
    
    // Wait before checking again
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
  
  throw new Error('Run timed out')
}

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }
  
  const { message, threadId, slug } = req.body
  
  if (!message) {
    return res.status(400).json({ error: 'Message is required' })
  }
  
  if (!slug && !threadId) {
    return res.status(400).json({ error: 'Either slug or threadId is required' })
  }
  
  try {
    let assistantId
    let currentThreadId = threadId
    
    // If no threadId provided, create a new thread and get assistant ID from slug
    if (!currentThreadId) {
      const companyData = await getCompanyAssistant(slug)
      
      if (!companyData || !companyData.assistantId) {
        return res.status(404).json({ error: 'Company or assistant not found' })
      }
      
      assistantId = companyData.assistantId
      
      // Create a new thread
      const thread = await retryWithBackoff(() => 
        openai.beta.threads.create()
      )
      currentThreadId = thread.id
    } else {
      // Get assistant ID from the first message in the thread
      const messages = await retryWithBackoff(() => 
        openai.beta.threads.messages.list(currentThreadId, { limit: 1 })
      )
      
      const run = await retryWithBackoff(() => 
        openai.beta.threads.runs.list(currentThreadId, { limit: 1 })
      )
      
      if (run.data.length > 0) {
        assistantId = run.data[0].assistant_id
      } else {
        // Fallback to getting assistant from slug
        const companyData = await getCompanyAssistant(slug)
        if (!companyData || !companyData.assistantId) {
          return res.status(404).json({ error: 'Assistant not found for this thread' })
        }
        assistantId = companyData.assistantId
      }
    }
    
    // Add the user message to the thread
    await retryWithBackoff(() => 
      openai.beta.threads.messages.create(currentThreadId, {
        role: 'user',
        content: message
      })
    )
    
    // Run the assistant
    const run = await retryWithBackoff(() => 
      openai.beta.threads.runs.create(currentThreadId, {
        assistant_id: assistantId
      })
    )
    
    // Wait for the run to complete
    await waitForRunCompletion(currentThreadId, run.id)
    
    // Get the latest messages
    const messages = await retryWithBackoff(() => 
      openai.beta.threads.messages.list(currentThreadId, { limit: 10 })
    )
    
    // Find the latest assistant message
    const assistantMessages = messages.data
      .filter(msg => msg.role === 'assistant')
      .sort((a, b) => new Date(b.created_at) - new Date(a.created_at))
    
    if (assistantMessages.length === 0) {
      return res.status(404).json({ error: 'No assistant response found' })
    }
    
    const latestMessage = assistantMessages[0]
    
    return res.status(200).json({
      threadId: currentThreadId,
      message: latestMessage.content[0].text.value,
      messageId: latestMessage.id
    })
  } catch (error) {
    console.error('Chat API error:', error)
    return res.status(500).json({
      error: 'Failed to process chat message',
      details: error.message
    })
  }
}
```

# Test Strategy:
1. Test chat functionality with various message types and lengths
2. Verify thread creation and management works correctly
3. Test timeout handling by simulating slow responses
4. Validate retry logic by temporarily introducing API failures
5. Test thread continuity across multiple messages
6. Verify error handling for various failure scenarios
7. Load test with multiple concurrent chat sessions
